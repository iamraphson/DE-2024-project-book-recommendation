[2024-03-25T19:53:54.832+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Book-Recommendation-DAG.do_upload_pq_to_gcs_task manual__2024-03-25T19:53:43.707646+00:00 [queued]>
[2024-03-25T19:53:54.837+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Book-Recommendation-DAG.do_upload_pq_to_gcs_task manual__2024-03-25T19:53:43.707646+00:00 [queued]>
[2024-03-25T19:53:54.837+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 3
[2024-03-25T19:53:54.843+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): do_upload_pq_to_gcs_task> on 2024-03-25 19:53:43.707646+00:00
[2024-03-25T19:53:54.848+0000] {standard_task_runner.py:60} INFO - Started process 369 to run task
[2024-03-25T19:53:54.850+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'Book-Recommendation-DAG', 'do_upload_pq_to_gcs_task', 'manual__2024-03-25T19:53:43.707646+00:00', '--job-id', '218', '--raw', '--subdir', 'DAGS_FOLDER/book-recommendation-dag.py', '--cfg-path', '/tmp/tmp2e6yw50z']
[2024-03-25T19:53:54.853+0000] {standard_task_runner.py:88} INFO - Job 218: Subtask do_upload_pq_to_gcs_task
[2024-03-25T19:53:54.880+0000] {task_command.py:423} INFO - Running <TaskInstance: Book-Recommendation-DAG.do_upload_pq_to_gcs_task manual__2024-03-25T19:53:43.707646+00:00 [running]> on host 992e1288d09b
[2024-03-25T19:53:54.928+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='iamraphson' AIRFLOW_CTX_DAG_ID='Book-Recommendation-DAG' AIRFLOW_CTX_TASK_ID='do_upload_pq_to_gcs_task' AIRFLOW_CTX_EXECUTION_DATE='2024-03-25T19:53:43.707646+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-03-25T19:53:43.707646+00:00'
[2024-03-25T19:53:55.241+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/book-recommendation-dag.py", line 115, in do_upload_pq_to_gcs
    gcs.delete_dir(gcs_pq_store_path)
  File "pyarrow/_fs.pyx", line 616, in pyarrow._fs.FileSystem.delete_dir
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
FileNotFoundError: [Errno 2] google::cloud::Status(NOT_FOUND: Permanent error DeleteObject: No such object: book_recommendation_datalake_radiant-gateway-412001/book-recommendation-pq/ error_info={reason=notFound, domain=global, metadata={http_status_code=404}}). Detail: [errno 2] No such file or directory
[2024-03-25T19:53:55.250+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=Book-Recommendation-DAG, task_id=do_upload_pq_to_gcs_task, execution_date=20240325T195343, start_date=20240325T195354, end_date=20240325T195355
[2024-03-25T19:53:55.261+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 218 for task do_upload_pq_to_gcs_task ([Errno 2] google::cloud::Status(NOT_FOUND: Permanent error DeleteObject: No such object: book_recommendation_datalake_radiant-gateway-412001/book-recommendation-pq/ error_info={reason=notFound, domain=global, metadata={http_status_code=404}}). Detail: [errno 2] No such file or directory; 369)
[2024-03-25T19:53:55.289+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-03-25T19:53:55.306+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
